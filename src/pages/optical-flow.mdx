---
layout: ../layouts/PostLayout.astro
title: "Motion Fields and Optical Flow: Geometry, Constraints, and Robotics Implications"
author: "Chahat Deep Singh"
description: "From 3D camera/object motion to 2D image motion: motion fields, optical flow, constraints, Lucas–Kanade, failure modes, and why the distinction matters in robotics."
date: "January 18, 2026"
image: "images/optical-flow.png"
tags: ["computer-vision", "optical-flow", "motion-fields", "geometry", "robotics"]
featured: false
---

## Learning Objectives

By the end of this lecture, you should be able to:

- Distinguish **motion fields** (true projected image motion induced by 3D motion) from **optical flow** (estimated image motion).
- Derive the **motion field equations** for camera translation and rotation.
- Explain why optical flow is **fundamentally ill-posed** without additional constraints.
- Understand the **brightness constancy constraint** and its consequences.
- Identify **failure modes** of optical flow that matter in robotics systems.
- Explain where **Lucas–Kanade** fits—and what it does *not* solve.

---

## 1. Image Motion Is Not a Primitive Quantity

In robotics and vision pipelines, “optical flow” is often treated as a primitive sensor measurement. This is incorrect.

There is no such thing as *true optical flow* in the physical world.

What exists physically is **3D motion**:
- of the camera,
- of objects,
- or both.

What we observe in images is the **projection of this 3D motion onto the image plane**.

This projection is called the **motion field**.

---

## 2. Motion Field: Definition

The **motion field** is the 2D velocity of image points induced by known 3D motion and scene geometry.

Formally:
- Let a 3D point $X(t)$ project to image coordinates $(x(t), y(t))$.
- The **motion field** is $(\dot{x}, \dot{y})$, obtained by differentiating the projection equations.

Crucially:
- The motion field **depends on depth**.
- It is **well-defined** even in textureless regions.
- It is **not directly observable** from image intensities alone.

---

## 3. Optical Flow: What It Actually Is

**Optical flow** is an *estimate* of image motion computed from brightness patterns over time.

It is:
- An *inference problem*, not a geometric one.
- Dependent on assumptions about the scene, lighting, and noise.
- Undefined where those assumptions fail.

The common but incorrect identification  
> *optical flow = image motion*  

is the root cause of many robotics failures.

---

## 4. Brightness Constancy Constraint

Most optical flow methods begin with the **brightness constancy assumption**:

$$
I(x, y, t) = I(x + \delta x, y + \delta y, t + \delta t)
$$

Linearizing yields the **optical flow constraint equation**:

$$
I_x u + I_y v + I_t = 0
$$

This is:
- One equation
- Two unknowns $(u, v)$

Therefore, **the problem is underdetermined**.

This is not a numerical issue.  
It is a **structural ambiguity**.

---

## 5. Aperture Problem (Not a Corner Case)

The aperture problem is not a pathological edge case—it is the *generic situation*.

- Along edges: motion perpendicular to the gradient is unobservable.
- In uniform regions: motion is completely unconstrained.

Any method that claims to “solve optical flow” without additional assumptions is mathematically incorrect.

---

## 6. Lucas–Kanade: What It Assumes

The **Lucas–Kanade** method resolves the ambiguity by assuming:

- Motion is **locally constant** within a small window.

This converts the underdetermined problem into a least-squares system.

Important consequences:
- It works **only where intensity gradients span multiple directions** (i.e., corners).
- It fails silently in low-texture regions.
- It does not recover the true motion field—only a *regularized estimate*.

Lucas–Kanade is an estimator, not a physical model.

---

## 7. Motion Field from Camera Motion (Key Result)

For a calibrated camera with focal length $f$, the motion field induced by:
- translational velocity $T = (T_x, T_y, T_z)$,
- rotational velocity $\omega = (\omega_x, \omega_y, \omega_z)$,

can be written as:

$$
u = \frac{-fT_x + xT_z}{Z} + xy\omega_x - (f^2 + x^2)\omega_y + y\omega_z
$$

$$
v = \frac{-fT_y + yT_z}{Z} + (f^2 + y^2)\omega_x - xy\omega_y - x\omega_z
$$

Key observations:
- **Translation depends on depth** $Z$.
- **Rotation does not**.
- Optical flow algorithms cannot separate these without additional information.

---

## 8. Why This Matters in Robotics

Confusing optical flow with motion fields leads to:

- Incorrect ego-motion estimates
- Spurious obstacle detection
- Control instability
- Dataset-specific “success” that collapses in deployment

In robotics:
- Optical flow is a *cue*, not a measurement.
- Geometry and dynamics must come first.

---

## 9. Summary (Non-Negotiable Facts)

- Motion fields are **physically defined**; optical flow is **inferred**.
- Optical flow is **ill-posed** without assumptions.
- Lucas–Kanade does not “solve” optical flow—it regularizes it.
- Depth is inseparable from translation-induced image motion.
- Treating optical flow as ground truth is a category error.

If you remember only one thing:

> **Optical flow is not motion. It is an estimate conditioned on assumptions.**

---
